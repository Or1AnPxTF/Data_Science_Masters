{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c597e63",
   "metadata": {},
   "source": [
    "### Q1. A company conducted a survey of its employees and found that 70% of the employees use the company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the probability that an employee is a smoker given that he/she uses the health insurance plan?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581dec51",
   "metadata": {},
   "source": [
    "P(Smoker | Uses Health Insurance) = P(Smoker and Uses Health Insurance) / P(Uses Health Insurance)\n",
    "\n",
    "Given,\n",
    "\n",
    "* The probability that an employee uses the health insurance plan is 70%, which can be denoted as P(Uses Health Insurance) = 0.70.\n",
    "\n",
    "* The probability that an employee who uses the plan is a smoker is 40%, which can be denoted as P(Smoker and Uses Health Insurance) = 0.40.\n",
    "\n",
    "Now, you can calculate the conditional probability:\n",
    "\n",
    "P(Smoker | Uses Health Insurance) = P(Smoker and Uses Health Insurance) / P(Uses Health Insurance)\n",
    "P(Smoker | Uses Health Insurance) = 0.40 / 0.70\n",
    "P(Smoker | Uses Health Insurance) ≈ 0.5714\n",
    "\n",
    "So, the probability that an employee is a smoker given that he/she uses the health insurance plan is approximately 57.14%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75d4a5f",
   "metadata": {},
   "source": [
    "### Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0df0e7",
   "metadata": {},
   "source": [
    "Ans)**Bernoulli Naive Bayes** and **Multinomial Naive Bayes** are both variants of the Naive Bayes classification algorithm, but they differ primarily in the type of data they are designed to handle. Bernoulli Naive Bayes is suitable for binary or boolean features, meaning it works best when the data represents the presence or absence of features. For example, in text classification tasks like spam detection, Bernoulli Naive Bayes considers whether a particular word appears in a document or not, ignoring how many times it occurs. It uses the Bernoulli distribution to model the binary occurrence of features.\n",
    "\n",
    "On the other hand, Multinomial Naive Bayes is used for data that involves discrete counts, making it ideal for tasks where the frequency of features matters. This variant is commonly applied in document classification, where the input features are typically word counts or term frequencies. Multinomial Naive Bayes uses the multinomial distribution to model the probability of word occurrences in a document, taking into account how often each word appears.\n",
    "\n",
    "In summary, while Bernoulli Naive Bayes focuses on the presence or absence of features, Multinomial Naive Bayes focuses on the number of times features occur. The choice between the two depends on the nature of the input data and the problem at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f630fe",
   "metadata": {},
   "source": [
    "### Q3. How does Bernoulli Naive Bayes handle missing values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e28d2f3",
   "metadata": {},
   "source": [
    "Bernoulli Naive Bayes, like other Naive Bayes variants, is not well-suited to handling missing values in its standard form. The algorithm assumes that each feature is either present (1) or absent (0), and it relies on these binary values to calculate probabilities for classification.\n",
    "\n",
    "When you have missing values in a Bernoulli Naive Bayes model, we can :\n",
    "\n",
    "1. Impute Missing Values: You can fill in the missing values with a suitable imputation technique. For binary data, you might impute missing values with the most common value (0 or 1) or use more advanced imputation methods, such as k-Nearest Neighbors imputation or predictive modeling techniques. However, the choice of imputation method can affect the results, so it should be done carefully.\n",
    "\n",
    "2. Remove Instances with Missing Values: Another approach is to remove instances (data points) that have missing values. This approach can work if the number of instances with missing values is relatively small and doesn't significantly impact the overall dataset. However, it can lead to a loss of information.\n",
    "\n",
    "3. Encode Missing Values as a Separate Category: Instead of imputing missing values, you can encode them as a separate category (e.g., -1 or \"missing\"). This approach retains the information that a value is missing and allows the Naive Bayes classifier to consider it as a separate feature. However, you should be cautious about how you handle these missing value categories during probability calculations.\n",
    "\n",
    "4. Modify the Algorithm: You could modify the Bernoulli Naive Bayes algorithm to handle missing values explicitly. This would involve adapting the probability calculations to account for missing values as a distinct category. However, this modification can be complex and might require redefining the basic assumptions of the Naive Bayes model.\n",
    "\n",
    "In practice, the choice of how to handle missing values depends on the specific dataset and problem at hand. It's important to consider the impact of missing data on your classification results and choose the most appropriate approach based on your data and the goals of your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a8490b",
   "metadata": {},
   "source": [
    "### Q4. Can Gaussian Naive Bayes be used for multi-class classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4164b1f",
   "metadata": {},
   "source": [
    "Yes, Gaussian Naive Bayes can be used for multi-class classification tasks. Gaussian Naive Bayes is a variant of the Naive Bayes algorithm that is specifically designed for continuous data where features are assumed to follow a Gaussian (normal) distribution. It can be adapted for multi-class classification by extending the basic binary classification setup.\n",
    "\n",
    "Using Gaussian Naive Bayes for multi-class classification:\n",
    "\n",
    "1. Data Preparation: Ensure that your dataset is appropriately prepared, and your features are continuous variables or can be approximated as continuous. If you have categorical features, you may need to convert them into continuous representations, such as using one-hot encoding.\n",
    "\n",
    "2. Model Training: When using Gaussian Naive Bayes for multi-class classification, you will create a separate model for each class. For example, if you have K classes, you would train K separate Gaussian Naive Bayes models, each one corresponding to a different class.\n",
    "\n",
    "3. Probability Estimation: In each model, you estimate the mean and variance of each feature for the instances belonging to that class. You assume that the features are normally distributed within each class. This estimation is typically done using the maximum likelihood method.\n",
    "\n",
    "4. Class Prediction: To classify a new data point, you calculate the likelihood of the data point belonging to each class based on the Gaussian probability density function with the estimated mean and variance for each feature in that class. You then use Bayes' theorem to calculate the posterior probability of each class, given the observed data, and assign the class with the highest posterior probability as the predicted class for the data point.\n",
    "\n",
    "In summary, Gaussian Naive Bayes can be used for multi-class classification by treating each class as a separate binary classification problem and using Gaussian probability density functions to model the feature distributions within each class. It's a simple and effective algorithm for multi-class classification when your data is continuous or can be reasonably approximated as such."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f683c43",
   "metadata": {},
   "source": [
    "### Q5. Assignment:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86df88ae",
   "metadata": {},
   "source": [
    "* Data preparation:\n",
    "Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message is spam or not based on several input features.\n",
    "\n",
    "* Implementation:\n",
    "Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the dataset. You should use the default hyperparameters for each classifier.\n",
    "\n",
    "* Results:\n",
    "Report the following performance metrics for each classifier: Accuracy Precision Recall F1 score\n",
    "\n",
    "* Discussion:\n",
    "Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is the case? Are there any limitations of Naive Bayes that you observed?\n",
    "\n",
    "* Conclusion:\n",
    "Summarise your findings and provide some suggestions for future work. Note: This dataset contains a binary classification problem with multiple features. The dataset is relatively small, but it can be used to demonstrate the performance of the different variants of Naive Bayes on a real-world problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de071bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB,MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0158833e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| SPAM E-MAIL DATABASE ATTRIBUTES (in .names format)\n",
      "|\n",
      "| 48 continuous real [0,100] attributes of type word_freq_WORD \n",
      "| = percentage of words in the e-mail that match WORD,\n",
      "| i.e. 100 * (number of times the WORD appears in the e-mail) / \n",
      "| total number of words in e-mail.  A \"word\" in this case is any \n",
      "| string of alphanumeric characters bounded by non-alphanumeric \n",
      "| characters or end-of-string.\n",
      "|\n",
      "| 6 continuous real [0,100] attributes of type char_freq_CHAR\n",
      "| = percentage of characters in the e-mail that match CHAR,\n",
      "| i.e. 100 * (number of CHAR occurences) / total characters in e-mail\n",
      "|\n",
      "| 1 continuous real [1,...] attribute of type capital_run_length_average\n",
      "| = average length of uninterrupted sequences of capital letters\n",
      "|\n",
      "| 1 continuous integer [1,...] attribute of type capital_run_length_longest\n",
      "| = length of longest uninterrupted sequence of capital letters\n",
      "|\n",
      "| 1 continuous integer [1,...] attribute of type capital_run_length_total\n",
      "| = sum of length of uninterrupted sequences of capital letters\n",
      "| = total number of capital letters in the e-mail\n",
      "|\n",
      "| 1 nominal {0,1} class attribute of type spam\n",
      "| = denotes whether the e-mail was considered spam (1) or not (0), \n",
      "| i.e. unsolicited commercial e-mail.  \n",
      "|\n",
      "| For more information, see file 'spambase.DOCUMENTATION' at the\n",
      "| UCI Machine Learning Repository: http://www.ics.uci.edu/~mlearn/MLRepository.html\n",
      "\n",
      "\n",
      "1, 0.    | spam, non-spam classes\n",
      "\n",
      "word_freq_make:         continuous.\n",
      "word_freq_address:      continuous.\n",
      "word_freq_all:          continuous.\n",
      "word_freq_3d:           continuous.\n",
      "word_freq_our:          continuous.\n",
      "word_freq_over:         continuous.\n",
      "word_freq_remove:       continuous.\n",
      "word_freq_internet:     continuous.\n",
      "word_freq_order:        continuous.\n",
      "word_freq_mail:         continuous.\n",
      "word_freq_receive:      continuous.\n",
      "word_freq_will:         continuous.\n",
      "word_freq_people:       continuous.\n",
      "word_freq_report:       continuous.\n",
      "word_freq_addresses:    continuous.\n",
      "word_freq_free:         continuous.\n",
      "word_freq_business:     continuous.\n",
      "word_freq_email:        continuous.\n",
      "word_freq_you:          continuous.\n",
      "word_freq_credit:       continuous.\n",
      "word_freq_your:         continuous.\n",
      "word_freq_font:         continuous.\n",
      "word_freq_000:          continuous.\n",
      "word_freq_money:        continuous.\n",
      "word_freq_hp:           continuous.\n",
      "word_freq_hpl:          continuous.\n",
      "word_freq_george:       continuous.\n",
      "word_freq_650:          continuous.\n",
      "word_freq_lab:          continuous.\n",
      "word_freq_labs:         continuous.\n",
      "word_freq_telnet:       continuous.\n",
      "word_freq_857:          continuous.\n",
      "word_freq_data:         continuous.\n",
      "word_freq_415:          continuous.\n",
      "word_freq_85:           continuous.\n",
      "word_freq_technology:   continuous.\n",
      "word_freq_1999:         continuous.\n",
      "word_freq_parts:        continuous.\n",
      "word_freq_pm:           continuous.\n",
      "word_freq_direct:       continuous.\n",
      "word_freq_cs:           continuous.\n",
      "word_freq_meeting:      continuous.\n",
      "word_freq_original:     continuous.\n",
      "word_freq_project:      continuous.\n",
      "word_freq_re:           continuous.\n",
      "word_freq_edu:          continuous.\n",
      "word_freq_table:        continuous.\n",
      "word_freq_conference:   continuous.\n",
      "char_freq_;:            continuous.\n",
      "char_freq_(:            continuous.\n",
      "char_freq_[:            continuous.\n",
      "char_freq_!:            continuous.\n",
      "char_freq_$:            continuous.\n",
      "char_freq_#:            continuous.\n",
      "capital_run_length_average: continuous.\n",
      "capital_run_length_longest: continuous.\n",
      "capital_run_length_total:   continuous.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('spambase.names','r') as f:\n",
    "    a = f.read()\n",
    "    \n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dd66588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Title:  SPAM E-mail Database\n",
      "\n",
      "2. Sources:\n",
      "   (a) Creators: Mark Hopkins, Erik Reeber, George Forman, Jaap Suermondt\n",
      "        Hewlett-Packard Labs, 1501 Page Mill Rd., Palo Alto, CA 94304\n",
      "   (b) Donor: George Forman (gforman at nospam hpl.hp.com)  650-857-7835\n",
      "   (c) Generated: June-July 1999\n",
      "\n",
      "3. Past Usage:\n",
      "   (a) Hewlett-Packard Internal-only Technical Report. External forthcoming.\n",
      "   (b) Determine whether a given email is spam or not.\n",
      "   (c) ~7% misclassification error.\n",
      "       False positives (marking good mail as spam) are very undesirable.\n",
      "       If we insist on zero false positives in the training/testing set,\n",
      "       20-25% of the spam passed through the filter.\n",
      "\n",
      "4. Relevant Information:\n",
      "        The \"spam\" concept is diverse: advertisements for products/web\n",
      "        sites, make money fast schemes, chain letters, pornography...\n",
      "\tOur collection of spam e-mails came from our postmaster and \n",
      "\tindividuals who had filed spam.  Our collection of non-spam \n",
      "\te-mails came from filed work and personal e-mails, and hence\n",
      "\tthe word 'george' and the area code '650' are indicators of \n",
      "\tnon-spam.  These are useful when constructing a personalized \n",
      "\tspam filter.  One would either have to blind such non-spam \n",
      "\tindicators or get a very wide collection of non-spam to \n",
      "\tgenerate a general purpose spam filter.\n",
      "\n",
      "        For background on spam:\n",
      "        Cranor, Lorrie F., LaMacchia, Brian A.  Spam! \n",
      "        Communications of the ACM, 41(8):74-83, 1998.\n",
      "\n",
      "5. Number of Instances: 4601 (1813 Spam = 39.4%)\n",
      "\n",
      "6. Number of Attributes: 58 (57 continuous, 1 nominal class label)\n",
      "\n",
      "7. Attribute Information:\n",
      "The last column of 'spambase.data' denotes whether the e-mail was \n",
      "considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  \n",
      "Most of the attributes indicate whether a particular word or\n",
      "character was frequently occuring in the e-mail.  The run-length\n",
      "attributes (55-57) measure the length of sequences of consecutive \n",
      "capital letters.  For the statistical measures of each attribute, \n",
      "see the end of this file.  Here are the definitions of the attributes:\n",
      "\n",
      "48 continuous real [0,100] attributes of type word_freq_WORD \n",
      "= percentage of words in the e-mail that match WORD,\n",
      "i.e. 100 * (number of times the WORD appears in the e-mail) / \n",
      "total number of words in e-mail.  A \"word\" in this case is any \n",
      "string of alphanumeric characters bounded by non-alphanumeric \n",
      "characters or end-of-string.\n",
      "\n",
      "6 continuous real [0,100] attributes of type char_freq_CHAR\n",
      "= percentage of characters in the e-mail that match CHAR,\n",
      "i.e. 100 * (number of CHAR occurences) / total characters in e-mail\n",
      "\n",
      "1 continuous real [1,...] attribute of type capital_run_length_average\n",
      "= average length of uninterrupted sequences of capital letters\n",
      "\n",
      "1 continuous integer [1,...] attribute of type capital_run_length_longest\n",
      "= length of longest uninterrupted sequence of capital letters\n",
      "\n",
      "1 continuous integer [1,...] attribute of type capital_run_length_total\n",
      "= sum of length of uninterrupted sequences of capital letters\n",
      "= total number of capital letters in the e-mail\n",
      "\n",
      "1 nominal {0,1} class attribute of type spam\n",
      "= denotes whether the e-mail was considered spam (1) or not (0), \n",
      "i.e. unsolicited commercial e-mail.  \n",
      "\n",
      "\n",
      "8. Missing Attribute Values: None\n",
      "\n",
      "9. Class Distribution:\n",
      "\tSpam\t  1813  (39.4%)\n",
      "\tNon-Spam  2788  (60.6%)\n",
      "\n",
      "\n",
      "Attribute Statistics:\n",
      "   Min: Max:   Average:  Std.Dev: Coeff.Var_%: \n",
      "1  0    4.54   0.10455   0.30536  292          \n",
      "2  0    14.28  0.21301   1.2906   606          \n",
      "3  0    5.1    0.28066   0.50414  180          \n",
      "4  0    42.81  0.065425  1.3952   2130         \n",
      "5  0    10     0.31222   0.67251  215          \n",
      "6  0    5.88   0.095901  0.27382  286          \n",
      "7  0    7.27   0.11421   0.39144  343          \n",
      "8  0    11.11  0.10529   0.40107  381          \n",
      "9  0    5.26   0.090067  0.27862  309          \n",
      "10 0    18.18  0.23941   0.64476  269          \n",
      "11 0    2.61   0.059824  0.20154  337          \n",
      "12 0    9.67   0.5417    0.8617   159          \n",
      "13 0    5.55   0.09393   0.30104  320          \n",
      "14 0    10     0.058626  0.33518  572          \n",
      "15 0    4.41   0.049205  0.25884  526          \n",
      "16 0    20     0.24885   0.82579  332          \n",
      "17 0    7.14   0.14259   0.44406  311          \n",
      "18 0    9.09   0.18474   0.53112  287          \n",
      "19 0    18.75  1.6621    1.7755   107          \n",
      "20 0    18.18  0.085577  0.50977  596          \n",
      "21 0    11.11  0.80976   1.2008   148          \n",
      "22 0    17.1   0.1212    1.0258   846          \n",
      "23 0    5.45   0.10165   0.35029  345          \n",
      "24 0    12.5   0.094269  0.44264  470          \n",
      "25 0    20.83  0.5495    1.6713   304          \n",
      "26 0    16.66  0.26538   0.88696  334          \n",
      "27 0    33.33  0.7673    3.3673   439          \n",
      "28 0    9.09   0.12484   0.53858  431          \n",
      "29 0    14.28  0.098915  0.59333  600          \n",
      "30 0    5.88   0.10285   0.45668  444          \n",
      "31 0    12.5   0.064753  0.40339  623          \n",
      "32 0    4.76   0.047048  0.32856  698          \n",
      "33 0    18.18  0.097229  0.55591  572          \n",
      "34 0    4.76   0.047835  0.32945  689          \n",
      "35 0    20     0.10541   0.53226  505          \n",
      "36 0    7.69   0.097477  0.40262  413          \n",
      "37 0    6.89   0.13695   0.42345  309          \n",
      "38 0    8.33   0.013201  0.22065  1670         \n",
      "39 0    11.11  0.078629  0.43467  553          \n",
      "40 0    4.76   0.064834  0.34992  540          \n",
      "41 0    7.14   0.043667  0.3612   827          \n",
      "42 0    14.28  0.13234   0.76682  579          \n",
      "43 0    3.57   0.046099  0.22381  486          \n",
      "44 0    20     0.079196  0.62198  785          \n",
      "45 0    21.42  0.30122   1.0117   336          \n",
      "46 0    22.05  0.17982   0.91112  507          \n",
      "47 0    2.17   0.0054445 0.076274 1400         \n",
      "48 0    10     0.031869  0.28573  897          \n",
      "49 0    4.385  0.038575  0.24347  631          \n",
      "50 0    9.752  0.13903   0.27036  194          \n",
      "51 0    4.081  0.016976  0.10939  644          \n",
      "52 0    32.478 0.26907   0.81567  303          \n",
      "53 0    6.003  0.075811  0.24588  324          \n",
      "54 0    19.829 0.044238  0.42934  971          \n",
      "55 1    1102.5 5.1915    31.729   611          \n",
      "56 1    9989   52.173    194.89   374          \n",
      "57 1    15841  283.29    606.35   214          \n",
      "58 0    1      0.39404   0.4887   124          \n",
      "\n",
      "\n",
      "This file: 'spambase.DOCUMENTATION' at the UCI Machine Learning Repository\n",
      "http://www.ics.uci.edu/~mlearn/MLRepository.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('spambase.DOCUMENTATION','r') as f:\n",
    "    b = f.read()\n",
    "    \n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ea58137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3     4     5     6     7     8     9   ...    48  \\\n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.00   \n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n",
       "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n",
       "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "\n",
       "      49   50     51     52     53     54   55    56  57  \n",
       "0  0.000  0.0  0.778  0.000  0.000  3.756   61   278   1  \n",
       "1  0.132  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n",
       "2  0.143  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n",
       "3  0.137  0.0  0.137  0.000  0.000  3.537   40   191   1  \n",
       "4  0.135  0.0  0.135  0.000  0.000  3.537   40   191   1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"spambase.data\",header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da61ce7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2788\n",
       "1    1813\n",
       "Name: 57, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[57].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67832aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "y = df[57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b37e5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da08b774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3450, 57), (1151, 57))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape , X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f46cf02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3450,), (1151,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c053bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classifiers\n",
    "bernoulli_nb = BernoulliNB()\n",
    "multinomial_nb = MultinomialNB()\n",
    "gaussian_nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d45023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 10-fold cross-validation and compute mean accuracy\n",
    "bernoulli_scores = cross_val_score(bernoulli_nb, X, y, cv=10, scoring='accuracy')\n",
    "multinomial_scores = cross_val_score(multinomial_nb, X, y, cv=10, scoring='accuracy')\n",
    "gaussian_scores = cross_val_score(gaussian_nb, X, y, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4f81c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean accuracy for each classifier\n",
    "mean_bernoulli_accuracy = bernoulli_scores.mean()\n",
    "mean_multinomial_accuracy = multinomial_scores.mean()\n",
    "mean_gaussian_accuracy = gaussian_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb041be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes Mean Accuracy: 0.8839380364047911\n",
      "Multinomial Naive Bayes Mean Accuracy: 0.7863496180326323\n",
      "Gaussian Naive Bayes Mean Accuracy: 0.8217730830896915\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "print(\"Bernoulli Naive Bayes Mean Accuracy:\", mean_bernoulli_accuracy)\n",
    "print(\"Multinomial Naive Bayes Mean Accuracy:\", mean_multinomial_accuracy)\n",
    "print(\"Gaussian Naive Bayes Mean Accuracy:\", mean_gaussian_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "166b9315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def performance_metrics_calculation(xtest,ytest,model):\n",
    "    y_pred= model.predict(xtest)\n",
    "    print(f\"Accuracy : {accuracy_score(ytest,y_pred)}\")\n",
    "    print(\"-----------------------------------------------\")\n",
    "    print(f\"Classification Report: \\n\\n {classification_report(ytest,y_pred)}\")\n",
    "    print(\"-----------------------------------------------\")\n",
    "    print(\"Confusion Matrix :\")\n",
    "    value = confusion_matrix(ytest,y_pred)\n",
    "    sns.heatmap(value,annot=True,fmt = \".1f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63ee4868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8827106863596872\n",
      "-----------------------------------------------\n",
      "Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90       676\n",
      "           1       0.90      0.80      0.85       475\n",
      "\n",
      "    accuracy                           0.88      1151\n",
      "   macro avg       0.89      0.87      0.88      1151\n",
      "weighted avg       0.88      0.88      0.88      1151\n",
      "\n",
      "-----------------------------------------------\n",
      "Confusion Matrix :\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bernoulli_nb.fit(X_train,y_train)\n",
    "performance_metrics_calculation(X_test,y_test,bernoulli_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9576cdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.7914856646394439\n",
      "-----------------------------------------------\n",
      "Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       676\n",
      "           1       0.77      0.71      0.74       475\n",
      "\n",
      "    accuracy                           0.79      1151\n",
      "   macro avg       0.79      0.78      0.78      1151\n",
      "weighted avg       0.79      0.79      0.79      1151\n",
      "\n",
      "-----------------------------------------------\n",
      "Confusion Matrix :\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "multinomial_nb.fit(X_train,y_train)\n",
    "performance_metrics_calculation(X_test,y_test,multinomial_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29b6a312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8271068635968722\n",
      "-----------------------------------------------\n",
      "Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.74      0.83       676\n",
      "           1       0.72      0.95      0.82       475\n",
      "\n",
      "    accuracy                           0.83      1151\n",
      "   macro avg       0.84      0.84      0.83      1151\n",
      "weighted avg       0.86      0.83      0.83      1151\n",
      "\n",
      "-----------------------------------------------\n",
      "Confusion Matrix :\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD7CAYAAABUt054AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWfUlEQVR4nO3deXhU5dnH8e8dxA3ZCRgIFSxYWS7FitS6vbhUllbBKhTaWt6+aKxii9YV19qWSqu40Io2iJW2CqZ1AalaFsUNK6AiskoUlRQkIFtABZK53z8yxtEkk4lM8mQOv0+vc83MM2d5pqY/n97nOeeYuyMiIvUvK3QHRET2VQpgEZFAFMAiIoEogEVEAlEAi4gEogAWEQlEASwiUg0ze8/M3jKzxWa2KN7Wysxmm9nq+GvLhPXHmFmhma0ys3417V8BLCKS3Knu3svde8c/XwvMdfeuwNz4Z8ysOzAM6AH0ByaaWaNkO96v7vpcbs+md3Wlh1Tyq943hO6CNEBj33vY9nYftcmcxm0O/yrHGwT0jb+fAswDrom3T3P3XcAaMysE+gCvVLcjjYBFJFpiZSkvZpZnZosSlrwv7c2BWWb2WsJ37dx9PUD8tW28vQOwNmHbonhbtep8BCwiUq88lvqq7vlAfpJVTnT3dWbWFphtZiuTrFvVaDrpaFwBLCLREks9gGvi7uvir8Vm9jjlJYUNZpbj7uvNLAcojq9eBHRM2DwXWJds/ypBiEikuMdSXpIxsyZm1vSz98CZwFJgBjAivtoIYHr8/QxgmJkdYGadga7AgmTH0AhYRKKlrDRde2oHPG5mUJ6VD7v7M2a2ECgws5HAB8AQAHdfZmYFwHKgFBjl7mXJDqAAFpFoiSXNvJS5+7vA0VW0fwScXs02Y4GxqR5DASwi0VKLk3ChKYBFJFrSeBKurimARSRSajq51pAogEUkWjQCFhEJpGxP6B6kTAEsItGiEoSISCAqQYiIBKIRsIhIIBoBi4iE4TGdhBMRCUMjYBGRQFQDFhEJJE0346kPCmARiRaNgEVEAlENWEQkkPTdkL3OKYBFJFo0AhYRCaOGpwA1KApgEYkWjYBFRALRLAgRkUA0AhYRCUSzIEREAlEJQkQkEJUgREQCUQCLiASiEoSISCA6CSciEohKECIigagEISISiEbAIiKBKIBFRAJxD92DlCmARSRaSjULQkQkDJ2EExEJRDVgEZFAVAMWEQkkg0bAWaE7ICKSVrFY6ksKzKyRmb1hZjPjn1uZ2WwzWx1/bZmw7hgzKzSzVWbWr6Z9K4BFJFK8rCzlJUWjgRUJn68F5rp7V2Bu/DNm1h0YBvQA+gMTzaxRsh0rgEUkWtI4AjazXOC7wP0JzYOAKfH3U4DBCe3T3H2Xu68BCoE+yfavABaRaPFYyouZ5ZnZooQl70t7uwu4GkhM63buvh4g/to23t4BWJuwXlG8rVo6CSci0RJLfRaEu+cD+VV9Z2bfA4rd/TUz65vC7qyqQyTbQAEsItGSvlkQJwJnm9lA4ECgmZn9HdhgZjnuvt7McoDi+PpFQMeE7XOBdckOoBKEiERLWVnqSxLuPsbdc929E+Un15519x8DM4AR8dVGANPj72cAw8zsADPrDHQFFiQ7hkbAe+HMc0fQ5OCDycrKolGjRhQ8MIFt20u44sZbWffhBtof2o7xvxlD82ZNmb/gde667y/s2VNK48b7ccWokXzr2F6V9lnd9pIZvv+HPL5x2jHs/Gg7E/pdA8AP/vRzsg/PAeDAZk34dPtO/jTwuoptmrdvzejZt/HsXY/y0qR/VdrnQc2bMOxPv6BFbjZbizYyddQEPt2+s35+UCaq+3nA44ACMxsJfAAMAXD3ZWZWACwHSoFR7p405c3r+KqRPZvezZzLUmrpzHNH8MjkCbRs0byibfw9k2nerCkXnD+U+/9WwPaSEn55yUhWvF1I65YtaZvdmtXvvsdFl9/As9P/Xmmf1W0fNb/qfUPoLtSJTn2OZPfOTznvjosrAjjRgOt/xKclH/PchMcr2obfexkec4oWF1YZwP2uHc4n23bwwr1PcsrFZ3FQ8yb8e9y0Ov0doYx97+Gq6qi18vHtF6ScOQdfef9eH29vqASRZs+9+AqDBpwBwKABZ/DsC68A0O2ILrTNbg1Al86HsWv3bnbv3p3y9pIZ3luwko+37aj2+57fPZ4lMz7/Z9rtzN5s+aCY4tVF1W7T7TvH8sY/XwTgjX++SLfv9E5fh6OoFrMgQquxBGFmR1I+v60D5Wf01gEz3H1F0g33AWZG3uXXY2YMGTSAIYMG8tGWrWS3aQVAdptWbN66rdJ2s+e9RLcjvs7+++9f6btUtpfM1KnPkezctI2P3vsQgMYHHcApPzuLv/z4d5yU971qtzskuzklG7cCULJxK4e0aV7tukKtZkGEljSAzewaYDgwjc+LybnAVDOb5u7jqtkuD8gDmDj+t1zwk+Hp63ED8rd7x9M2uzUfbdnKhZddR+fDOta4TeG773PHxAfIv3NsPfRQGpKjzj6BN2fMr/h8+uXn8vLkp9j98a6AvYoez6B7QdQ0Ah4J9HD3PYmNZnYHsIzyYnQliXProlwD/qyk0LplC04/5QTeWr6K1i1bsHHTZrLbtGLjps20SqgPf1i8kdHX/Ybf3XglX8ttX+U+k20vmSurURY9+h3HPWddX9HWsVcXeg78Fv3H/JADmx2Mx5zSXXv4z19nfWHbHRu30TS7BSUbt9I0uwU7Nun/FSWV+iXGwdVUA44BVSVFDl+8MmSf8/Enn7Jz58cV7+cveJ2uh3ei70nHM/3pOQBMf3oOp578bQC2l+zgkqtu5rKL/pdvHtWj2v1Wt71ktq+f1JON765j+4ebK9omDf01t580mttPGs38B57h+XumVwpfgJVzXueY804G4JjzTmbF7Nfqrd8ZKeapL4HVNAK+DJhrZqv5/BK7rwFdgEvrsF8N3kebtzD6ut8AUFZaxsAz+3LS8b3p2e0Irrjxdzw289/ktMvmjt+Wj3imPvoka4vWcd+DU7nvwakA5N81ltYtW3DTrXcxdPBAenY7ggvOH1rl9pIZhk64lMOP78bBLZty9St/ZO6dj/JawTyOOuvbLEkoP9TknHEXsuChOfz3rTU8f+8Mht/zC44deirb1m1i6iV31+EviIAMKkHUOA3NzLIov6FEB8ovtSsCFtY0v+0zUS5ByFcX1WlosnfSMQ1t503DUs6cJr+eFnQaWo2zINw9BvynHvoiIrL3GsD0slTpSjgRiZYGUNtNlQJYRCLFSzNnFoQCWESiRSNgEZFAVAMWEQlEI2ARkTBcASwiEohOwomIBKIRsIhIIApgEZEw6vopP+mkABaRaNEIWEQkEAWwiEgYXqoLMUREwsic/FUAi0i06EIMEZFQFMAiIoGoBCEiEoZKECIigXipAlhEJAyVIEREwsig+7ErgEUkYhTAIiJhaAQsIhKIl4buQeoUwCISKRoBi4gEogAWEQnFLXQPUqYAFpFIyaQRcFboDoiIpJPHLOUlGTM70MwWmNmbZrbMzG6Jt7cys9lmtjr+2jJhmzFmVmhmq8ysX019VQCLSKTEyizlpQa7gNPc/WigF9DfzI4HrgXmuntXYG78M2bWHRgG9AD6AxPNrFGyAyiARSRSPJb6knQ/5XbEPzaOLw4MAqbE26cAg+PvBwHT3H2Xu68BCoE+yY6hABaRSKlNCcLM8sxsUcKSl7gvM2tkZouBYmC2u78KtHP39QDx17bx1TsAaxM2L4q3VUsn4UQkUmrzVHp3zwfyk3xfBvQysxbA42bWM8nuqqppJO2NAlhEIqWmk2tfaZ/uW81sHuW13Q1mluPu680sh/LRMZSPeDsmbJYLrEu2X5UgRCRS0nUSzsyy4yNfzOwg4AxgJTADGBFfbQQwPf5+BjDMzA4ws85AV2BBsmNoBCwikZLGEXAOMCU+kyELKHD3mWb2ClBgZiOBD4AhAO6+zMwKgOVAKTAqXsKolgJYRCLF03QlnLsvAY6pov0j4PRqthkLjE31GApgEYmUTLoSTgEsIpES070gRETCSFcJoj4ogEUkUlK4xLjBUACLSKTUxTzguqIAFpFIUQ1YRCQQ1YBFRAKpzb0gQlMAi0ikqAQhIhJITCfhRETC0Ag4wUHtT67rQ0gG2jF3XOguSETpJJyISCAaAYuIBJJBkyAUwCISLWWxzHnOhAJYRCIlg+5GqQAWkWjxKp+N2TApgEUkUmIZVARWAItIpMQ0AhYRCUMlCBGRQMoUwCIiYWgWhIhIIApgEZFAVAMWEQkkg+5GqQAWkWjRNDQRkUDKQnegFhTAIhIpMdMIWEQkiAy6ElkBLCLRomloIiKBaBaEiEgguhRZRCQQjYBFRAJRDVhEJBDNghARCUQlCBGRQDKpBJE5z28WEUlBmaW+JGNmHc3sOTNbYWbLzGx0vL2Vmc02s9Xx15YJ24wxs0IzW2Vm/WrqqwJYRCIlVoulBqXAFe7eDTgeGGVm3YFrgbnu3hWYG/9M/LthQA+gPzDRzBolO4ACWEQiJV0B7O7r3f31+PsSYAXQARgETImvNgUYHH8/CJjm7rvcfQ1QCPRJdgwFsIhEitdiMbM8M1uUsORVtU8z6wQcA7wKtHP39VAe0kDb+GodgLUJmxXF26qlk3AiEim1mQXh7vlAfrJ1zOwQ4FHgMnffbtXfba2qL5LOitMIWEQiJY01YMysMeXh+5C7PxZv3mBmOfHvc4DieHsR0DFh81xgXbL9K4BFJFLKarEkY+VD3cnACne/I+GrGcCI+PsRwPSE9mFmdoCZdQa6AguSHUMlCBGJlDReiHEicD7wlpktjrddB4wDCsxsJPABMATA3ZeZWQGwnPIZFKPcPWnOK4BFJFLSdSGGu79E1XVdgNOr2WYsMDbVYyiARSRSdC8IEZFAYhkUwQpgEYkUPRVZRCSQTLoZjwJYRCJFt6MUEQlENWARkUAyJ34VwCISMaoBi4gEUpZBY2AFsIhEikbAIiKB6CSciEggmRO/CmARiRiVIEREAtFJOBGRQDKpBqwnYqRBbm575sz6B28tmcebi5/l55eOBOCmG3/J+2sWsWjhLBYtnMWA/qdVuX2/M/uybOkLrFz+EldfNao+uy51oCwWY+gtk7h0wjQA7p3+PGdceTdDb5nE0Fsm8eKSwop1Jz/1Mt8bcw9nXz+Rl5e+U+X+tu34hIvGP8RZ193DReMfYvvOT+rld2Sq2jyUMzSNgNOgtLSUq66+hTcWL+WQQ5qw4NVnmDP3BQDunjCJO+78c7XbZmVlMeHusfQfOJyiovX855WneHLmLFasWF1f3Zc0e2jOAg7PacOOT3dVtJ3/nT6M6PftL6z3zrqNPLNgGY/9+iKKt5Zw0R0PMWPsJTTK+uK46IGn59OnWydGDjyRyU+9zOSn53P5eVXeD1zQCHif8+GHxbyxeCkAO3bsZOXK1XRof2hK2/Y57hjeeec91qz5gD179lBQMJ2zz+pXl92VOrRh83ZeXFLIOSf3qnHdeYvfpn+fHuzfeD9ys1vSsW0rlq6p/AzH5xav4uwTjgLg7BOO4rk3VqW725GSzody1jUFcJoddlguvY7uyasL3gDgkot/yuuvzWZS/nhatGheaf32HQ5lbdHn/6Mr+u962qcY3tLw/OGRWVx+3ulkfenR5dOeXcR5N+dz01+erCghbNhSQruWzSrWadeyKcVbSirtc/P2nWS3aApAdoumbC75uA5/QebzWvwntDoJYDPLM7NFZrYoFttZF4dokJo0OZiCRybxyytvpqRkB/f9+a8cceQJHNv7TD78sJjb/nBTpW3MKt87zz38H4bU3vNvrqZV0yZ075TzhfahfY9l5q2jKLj5QrKbH8LtBXPi31T+51zFn4PUUhme8hLaVw5gM/tpdd+5e76793b33llZTb7qITLKfvvtxz8emcTUqY/zxBNPA1BcvIlYLIa7c//khzjuuF6Vtvtv0Xo65rav+JzbIYf16zfUV7cljRYXrmXem28z4Jo/ck3+4yxc+R5jJj1B6+aH0Cgri6ws4/unHFNRZmjXshkbtmyv2H7DlpKKkW6iVs2asHFr+ch449YSWjU9uH5+UIbaV0oQt6StFxEwKX88K1YWctfd+RVthx7atuL94EEDWLascu1u4aLFdOnSmU6dOtK4cWOGDh3EkzNn1UufJb1Gn3sas28bzdO//zm/zzuH447sxK0XDq4IT4BnX19Flw7ZAPzP0UfwzIJl7N5TStHGLXywYTM9O7evtN++vY5gxvwlAMyYv4RTe32jfn5Qhoq5p7yElnQWhJktqe4roF36u5OZTjzhOM7/8XkseWs5ixaWh+eNN47jBz8YzNFHd8fdef/9Ii6+5BoAcnLakX/fbZw16CeUlZUx+rIbeOpfD9MoK4sHpzzC8uVvh/w5kmZ3/nMuq9ZuwDDat2nOjecPBKBLh2zO7N2dc266j0ZZWVz3o/4VMyB+9eBMhvT9Jj06tef/BpzAVfc9xhMvLebQVs25/Wfnhvw5DV74WE2dJas3mtkGoB+w5ctfAfPdvfK/rr9kv/07ZNJ/H1JPdswdF7oL0gAdePL5e10F/+Fh56ScOQ+//3jQqntN84BnAoe4++Ivf2Fm8+qiQyIie6MhzG5IVdIAdveRSb77Yfq7IyKyd0qjEsAiIpkmMiNgEZFM0xCml6VKASwikZJJFzIpgEUkUjLpZjwKYBGJlIZwiXGqFMAiEikaAYuIBKIasIhIIJoFISISiOYBi4gEohqwiEggZZ45RQg9kkhEIiWdjyQyswfMrNjMlia0tTKz2Wa2Ov7aMuG7MWZWaGarzKzGhzsqgEUkUtJ8Q/YHgf5farsWmOvuXYG58c+YWXdgGNAjvs1EM2uUbOcKYBGJFK/FUuO+3F8ANn+peRAwJf5+CjA4oX2au+9y9zVAIdAn2f4VwCISKTE85SXxAcLxJS+FQ7Rz9/UA8dfPnj3WAVibsF5RvK1aOgknIpFSm1kQ7p4P5Ne4YmqqerpG0s4ogEUkUuphFsQGM8tx9/VmlgMUx9uLgI4J6+UC65LtSCUIEYmUdM6CqMYMYET8/QhgekL7MDM7wMw6A12BBcl2pBGwiERKOu8FYWZTgb5AGzMrAm4GxgEFZjYS+AAYEj/uMjMrAJYDpcAody9Ltn8FsIhESjqvhHP34dV8dXo1648Fxqa6fwWwiESK7oYmIhJIWQbdD00BLCKRkuIVbg2CAlhEIkW3oxQRCUQjYBGRQDQCFhEJRCNgEZFAMumG7ApgEYkUlSBERAJxjYBFRMLQQzlFRALRpcgiIoFoBCwiEkhZTDVgEZEgNAtCRCQQ1YBFRAJRDVhEJBCNgEVEAtFJOBGRQFSCEBEJRCUIEZFAdDtKEZFANA9YRCQQjYBFRAKJ6XaUIiJh6CSciEggCmARkUAyJ37BMunfFpnOzPLcPT90P6Rh0d/FvisrdAf2MXmhOyANkv4u9lEKYBGRQBTAIiKBKIDrl+p8UhX9XeyjdBJORCQQjYBFRAJRAIuIBKIAridm1t/MVplZoZldG7o/Ep6ZPWBmxWa2NHRfJAwFcD0ws0bAPcAAoDsw3My6h+2VNAAPAv1Dd0LCUQDXjz5Aobu/6+67gWnAoMB9ksDc/QVgc+h+SDgK4PrRAVib8Lko3iYi+zAFcP2wKto0/09kH6cArh9FQMeEz7nAukB9EZEGQgFcPxYCXc2ss5ntDwwDZgTuk4gEpgCuB+5eClwK/BtYARS4+7KwvZLQzGwq8ArwDTMrMrORofsk9UuXIouIBKIRsIhIIApgEZFAFMAiIoEogEVEAlEAi4gEogAWEQlEASwiEsj/A/5Ue7IehioBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gaussian_nb.fit(X_train,y_train)\n",
    "performance_metrics_calculation(X_test,y_test,gaussian_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34516c81",
   "metadata": {},
   "source": [
    "### Obervation :\n",
    "* From the comparison of various Naive Bayes algorithms we found out that Bernoulli NB is the best performing compared to Multinomial and Guassian NB.\n",
    "* The accuracy of the Bernoulli NB,Multinomial and Guassian NB after applying 10 fold cross validation is 88.39 , 78.63 and 82.17 respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab88c84",
   "metadata": {},
   "source": [
    "### Limitation of Naive Bayes:\n",
    "\n",
    "\n",
    "1. Assumption of Independence: Naive Bayes assumes that all features are conditionally independent given the class label. In reality, this independence assumption may not hold, and features might be correlated. This can lead to suboptimal results, especially when dealing with complex data.\n",
    "\n",
    "\n",
    "2. Sensitivity to Feature Distribution: Naive Bayes methods, especially Gaussian Naive Bayes, assume that features follow specific probability distributions (e.g., Gaussian, Bernoulli, or Multinomial). If this assumption doesn't match the actual data distribution, the model's performance can be negatively affected.\n",
    "\n",
    "\n",
    "3. Difficulty with Continuous Features: In practice, Gaussian Naive Bayes can struggle with continuous features because it assumes a Gaussian distribution for each feature. If the data doesn't follow this distribution, the model might not perform well.\n",
    "\n",
    "\n",
    "4. Zero Frequency Problem: In Multinomial Naive Bayes and Bernoulli Naive Bayes, if a feature-class combination has zero occurrences in the training data, it can lead to zero probabilities when applying Bayes' theorem. This issue can be addressed with smoothing techniques like Laplace smoothing.\n",
    "\n",
    "\n",
    "5. Data Imbalance: When dealing with imbalanced datasets (where one class significantly outnumbers another), Naive Bayes can be biased towards the majority class, as it assumes all classes are equally likely a priori.\n",
    "\n",
    "\n",
    "6. Lack of Feature Importance: Naive Bayes doesn't provide feature importance scores directly. Other algorithms like decision trees or gradient boosting models can offer more insights into which features are most influential in making predictions.\n",
    "\n",
    "\n",
    "7. Sensitive to Irrelevant Features: Naive Bayes can be sensitive to irrelevant features in the dataset. Even though it assumes independence, irrelevant features can still affect the model's performance.\n",
    "\n",
    "\n",
    "8. Difficulty Handling Missing Data: Naive Bayes doesn't handle missing data well, especially in the Gaussian variant, which relies on estimating mean and variance. Missing data can lead to incorrect probability estimates.\n",
    "\n",
    "\n",
    "9. Limited Support for Text Data: While Multinomial Naive Bayes is commonly used for text classification, it doesn't capture the semantic meaning of words or the order of words in a document. More advanced techniques like word embeddings or deep learning are better suited for natural language processing tasks.\n",
    "\n",
    "\n",
    "* Despite these limitations, Naive Bayes can still be a valuable and computationally efficient choice for certain types of classification problems, especially when the independence assumption aligns with the data and the dataset is not too complex."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
